# Market Predictor - Cursor Project Intelligence

## Project Overview
FastAPI-based Bitcoin price prediction service designed to be monitored and improved by an autonomous agent. This is the target system that will be continuously enhanced through automated PRs.

## Core Development Patterns

### 1. FastAPI Architecture
- Use FastAPI application factory pattern in `main.py`
- Separate API routes, business logic (services), and data models
- Leverage FastAPI's automatic OpenAPI documentation
- Use Pydantic V2 for all request/response validation
- Implement proper dependency injection for services

### 2. Monitoring-First Development
- Every endpoint must expose appropriate Prometheus metrics
- All logs should be structured JSON for Loki aggregation
- Health endpoints (`/health`, `/status`) are critical for agent monitoring
- Response times must be optimized for agent analysis

### 3. Configuration Management
- Use Pydantic Settings for type-safe configuration
- Environment variables for all configurable values
- Support for .env files in development
- Validate all configuration at startup

### 4. Error Handling Strategy
- Structured error responses with consistent format
- Proper HTTP status codes for different error types
- Graceful degradation when possible (e.g., return cached predictions)
- All errors must be logged for agent analysis

## Agent Integration Requirements

### 1. Observability for Agent
- `/metrics` endpoint for Prometheus scraping
- Structured logs that can be analyzed by LLM
- Health endpoints that provide detailed status information
- Performance metrics for all critical operations

### 2. Agent-Friendly API Design
- Consistent response formats for easy parsing
- Clear error messages that can be understood by LLM
- API versioning from the start (`/api/v1/`)
- Comprehensive OpenAPI documentation

### 3. Safe for Autonomous Improvement
- All changes must be backward compatible
- Graceful handling of configuration changes
- Ability to restart without data loss
- Clear separation between core logic and configuration

## Code Quality Standards

### 1. Type Safety
- Use Python 3.9+ type hints throughout
- Pydantic models for all data structures
- mypy type checking in CI/CD
- No `Any` types except for external library interfaces

### 2. Testing Requirements
- Unit tests for all business logic
- Integration tests for all API endpoints
- Performance tests for prediction endpoints
- Mock external dependencies appropriately

### 3. Code Organization
```
src/predictor/
├── main.py              # FastAPI app factory
├── api/                 # API layer
├── services/            # Business logic
├── models/              # Data models and prediction models
└── config/              # Configuration and settings
```

## Performance Considerations

### 1. Response Time Targets
- Health endpoints: < 10ms
- Prediction endpoints: < 100ms (95th percentile)
- Status endpoints: < 50ms
- Metrics endpoint: < 20ms

### 2. Caching Strategy
- Cache prediction responses with TTL
- Cache model metadata and configuration
- Use appropriate cache invalidation strategies
- Monitor cache hit rates

### 3. Resource Management
- Memory usage < 512MB under normal load
- CPU usage < 50% under normal load
- Graceful handling of resource constraints
- Connection pooling for external services

## Security Patterns

### 1. Input Validation
- Validate all inputs via Pydantic models
- Sanitize data before processing
- Rate limiting on prediction endpoints
- No sensitive data in logs or metrics

### 2. Monitoring Security
- Metrics endpoints should not expose sensitive data
- Health checks should not leak internal information
- Proper error handling to avoid information disclosure

## Development Workflow

### 1. Branch Strategy
- Feature branches for new functionality
- `main` branch is always deployable
- All changes via pull requests
- Agent will create PRs for improvements

### 2. Code Review Requirements
- All PRs require review before merge
- Automated tests must pass
- Code quality checks must pass
- Performance regression checks

### 3. Agent Considerations
- Agent will analyze this service continuously
- Agent may create PRs for improvements
- All agent changes will follow same review process
- Human oversight for agent-generated changes

## Common Patterns and Solutions

### 1. Prediction Model Interface
```python
class PredictionModel(ABC):
    @abstractmethod
    async def predict(self, input_data: Dict) -> PredictionResult:
        pass
    
    @abstractmethod
    def get_model_info(self) -> ModelInfo:
        pass
```

### 2. Metrics Collection
```python
# Use decorators for automatic metrics collection
@metrics.track_request_duration
@metrics.count_requests
async def predict_endpoint(request: PredictionRequest) -> PredictionResponse:
    pass
```

### 3. Error Response Format
```python
class APIError(BaseModel):
    error_code: str
    message: str
    details: Optional[Dict] = None
    timestamp: datetime
```

### 4. Health Check Pattern
```python
class HealthStatus(BaseModel):
    status: str  # "healthy", "degraded", "unhealthy"
    checks: Dict[str, bool]
    timestamp: datetime
```

## Agent-Specific Considerations

### 1. Metrics for Agent Analysis
- Request count, duration, error rate
- Prediction confidence scores and accuracy
- Model performance metrics
- Resource utilization metrics

### 2. Log Patterns for Agent
- Structured JSON logs with consistent fields
- Log levels: ERROR, WARN, INFO, DEBUG
- Include request IDs for tracing
- Performance markers for analysis

### 3. Configuration for Agent Control
- Runtime configuration via environment variables
- Ability to adjust logging levels
- Feature flags for experimental features
- Cache configuration for performance tuning

## Known Patterns to Avoid

### 1. Anti-Patterns
- Blocking I/O in async functions
- Storing state in global variables
- Hard-coded configuration values
- Unstructured error messages

### 2. Agent Compatibility Issues
- Inconsistent API response formats
- Missing or incomplete health checks
- Poor error handling that obscures root causes
- Metrics that don't provide actionable insights

## Future Evolution Guidelines

### 1. Scalability Preparation
- Design for horizontal scaling
- Stateless service architecture
- External state management (Redis, database)
- Load balancer friendly design

### 2. Model Evolution
- Support for multiple prediction models
- A/B testing framework for models
- Model versioning and rollback
- Performance comparison between models

### 3. Advanced Features
- Real-time prediction streaming
- Historical prediction tracking
- Advanced monitoring and alerting
- Integration with trading systems

This project is designed to evolve autonomously through agent-driven improvements while maintaining reliability and performance standards. 